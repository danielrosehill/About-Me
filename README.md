# About-Me

## Tech & AI

I'm enormously interested in exploring the many ways in which large language models can provide utility to everyday use cases (boring intro, I know, but let me warm up). 

My fascination with AI and LLMs took off in approximately February 2024 when ChatGPT wrote a Home Assistant YAML configuration and to my amazement it worked flawlessly on the first run.  Watching lights turn off in a sequence that a computer had successfully programmed on its own was both a lightbulb moment for me in a literal sense (pun intended!) and a breakthrough so exciting that I spent the night wondering what else they could do (beyond chat and generate funny images).

My fascination with AI so far has unfolded quite naturally in a series of evolutions. 

Having discovered that with some careful prompt engineering even chat interfaces could yield much value, the digital prepper in me kicked into overdrive and I began thinking about how these "outputs" (completions) could be preserved and organised so that they don't vanish into the digital either (output storage remains, sadly, a much neglected topic!)

Building my own modest CRUD interface to store these outputs then led to the second realisation: while numbers and statistical models are what's happening under the bonnet, text is the layer at which humans provide information to LLMs and get information back from them. Curating it is key to leveraging it to maximal effect. 

An unintended benefit of my careful curating of outputs was discovering that those same outputs could be mined for contextual data and then reintroduced in subsequent interactions.  This, in turn, stimulated an interest in how best to go about managing small pieces of contextual data to optimize that process. 

 One of my experiments-in-progress is a multi-agent system for proactively developing contextual data. The mechanics are simple: 

This laid the groundwork for exploring RAG and context management. 

 Among the datasets which I've shared on Hugging face-to-date is a sprawling array of about 600 system prompts distilled from a library of close on a thousand. Writing system prompts to me is the kernel of why I find AI so engrossing: it's given creatives, who find most earnest expression in natural language, a way to relate to technology not in code but in the way that comes most natural to them. 

It's made our exploration of technology less constrictive and it's an amazing new change unfolding.